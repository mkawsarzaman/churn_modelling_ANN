{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the first 3 columns as they have no significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(labels=['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('Exited',axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Exited'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the categorical columns, LabelEncoder for Gender (as only options are male and female), and OneHotEncoder for Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,2] = le.fit_transform(X[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(Dense(12, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(Dense(6, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "ann.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam', loss= 'binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.5206 - accuracy: 0.7790\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 0s 629us/step - loss: 0.4467 - accuracy: 0.8015\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 0s 590us/step - loss: 0.4273 - accuracy: 0.8164\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 0s 566us/step - loss: 0.4166 - accuracy: 0.8246\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 0s 579us/step - loss: 0.4090 - accuracy: 0.8279\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 0s 613us/step - loss: 0.4020 - accuracy: 0.8311\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 0s 650us/step - loss: 0.3946 - accuracy: 0.8344\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 0s 580us/step - loss: 0.3869 - accuracy: 0.8388\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 0s 564us/step - loss: 0.3787 - accuracy: 0.8422\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 0s 568us/step - loss: 0.3718 - accuracy: 0.8470\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 0s 589us/step - loss: 0.3655 - accuracy: 0.8494\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 0s 555us/step - loss: 0.3610 - accuracy: 0.8493\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 0s 611us/step - loss: 0.3567 - accuracy: 0.8533\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 0s 638us/step - loss: 0.3528 - accuracy: 0.8553\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 0s 556us/step - loss: 0.3488 - accuracy: 0.8577\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 0s 565us/step - loss: 0.3460 - accuracy: 0.8593\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 0s 577us/step - loss: 0.3433 - accuracy: 0.8597\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 0s 559us/step - loss: 0.3421 - accuracy: 0.8604\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 0s 572us/step - loss: 0.3406 - accuracy: 0.8605\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 0s 613us/step - loss: 0.3388 - accuracy: 0.8624\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 0s 587us/step - loss: 0.3380 - accuracy: 0.8620\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 0s 548us/step - loss: 0.3369 - accuracy: 0.8609\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 0s 579us/step - loss: 0.3361 - accuracy: 0.8614\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 0s 577us/step - loss: 0.3349 - accuracy: 0.8616\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 0s 563us/step - loss: 0.3340 - accuracy: 0.8635\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 0s 553us/step - loss: 0.3339 - accuracy: 0.8635\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 0s 567us/step - loss: 0.3325 - accuracy: 0.8637\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 0s 552us/step - loss: 0.3319 - accuracy: 0.8639\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 0s 554us/step - loss: 0.3309 - accuracy: 0.8661\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 0s 562us/step - loss: 0.3309 - accuracy: 0.8636\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3298 - accuracy: 0.8622\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 0s 544us/step - loss: 0.3301 - accuracy: 0.8644\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 0s 568us/step - loss: 0.3292 - accuracy: 0.8650\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 0s 547us/step - loss: 0.3292 - accuracy: 0.8639\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 0s 567us/step - loss: 0.3286 - accuracy: 0.8644\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 0s 558us/step - loss: 0.3289 - accuracy: 0.8648\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 0s 571us/step - loss: 0.3280 - accuracy: 0.8637\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 0s 563us/step - loss: 0.3279 - accuracy: 0.8643\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 0s 546us/step - loss: 0.3275 - accuracy: 0.8637\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 0s 567us/step - loss: 0.3274 - accuracy: 0.8649\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 0s 562us/step - loss: 0.3265 - accuracy: 0.8636\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 0s 562us/step - loss: 0.3271 - accuracy: 0.8651\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 0s 565us/step - loss: 0.3264 - accuracy: 0.8640\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 0s 566us/step - loss: 0.3266 - accuracy: 0.8655\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 0s 561us/step - loss: 0.3264 - accuracy: 0.8644\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 0s 539us/step - loss: 0.3263 - accuracy: 0.8634\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 0s 676us/step - loss: 0.3260 - accuracy: 0.8643\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 0s 649us/step - loss: 0.3257 - accuracy: 0.8658\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.3254 - accuracy: 0.8659\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 0s 542us/step - loss: 0.3251 - accuracy: 0.8670\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 0s 535us/step - loss: 0.3249 - accuracy: 0.8669\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 0s 562us/step - loss: 0.3247 - accuracy: 0.8660\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 0s 637us/step - loss: 0.3244 - accuracy: 0.8660\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 0s 593us/step - loss: 0.3243 - accuracy: 0.8679\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 0s 601us/step - loss: 0.3242 - accuracy: 0.8648\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 0s 629us/step - loss: 0.3238 - accuracy: 0.8648\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 0s 561us/step - loss: 0.3241 - accuracy: 0.8662\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 0s 554us/step - loss: 0.3237 - accuracy: 0.8676\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 0s 547us/step - loss: 0.3234 - accuracy: 0.8670\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3239 - accuracy: 0.8662\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 0s 550us/step - loss: 0.3238 - accuracy: 0.8660\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 0s 538us/step - loss: 0.3231 - accuracy: 0.8669\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 0s 571us/step - loss: 0.3232 - accuracy: 0.8676\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 0s 544us/step - loss: 0.3233 - accuracy: 0.8669\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 0s 533us/step - loss: 0.3227 - accuracy: 0.8674\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 0s 544us/step - loss: 0.3231 - accuracy: 0.8655\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 0s 535us/step - loss: 0.3231 - accuracy: 0.8654\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 0s 535us/step - loss: 0.3226 - accuracy: 0.8675\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 0s 551us/step - loss: 0.3227 - accuracy: 0.8676\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 0s 558us/step - loss: 0.3225 - accuracy: 0.8666\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 0s 566us/step - loss: 0.3219 - accuracy: 0.8661\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 0s 536us/step - loss: 0.3223 - accuracy: 0.8674\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 0s 538us/step - loss: 0.3224 - accuracy: 0.8679\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3219 - accuracy: 0.8671\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3224 - accuracy: 0.8668\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 0s 550us/step - loss: 0.3220 - accuracy: 0.8691\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 0s 562us/step - loss: 0.3226 - accuracy: 0.8670\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 0s 551us/step - loss: 0.3219 - accuracy: 0.8685\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 537us/step - loss: 0.3212 - accuracy: 0.8662\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 0s 541us/step - loss: 0.3216 - accuracy: 0.8683\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 0s 539us/step - loss: 0.3212 - accuracy: 0.8661\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 0s 526us/step - loss: 0.3215 - accuracy: 0.8674\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3213 - accuracy: 0.8668\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 0s 547us/step - loss: 0.3213 - accuracy: 0.8680\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 0s 531us/step - loss: 0.3214 - accuracy: 0.8675\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 0s 561us/step - loss: 0.3212 - accuracy: 0.8686\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 0s 544us/step - loss: 0.3211 - accuracy: 0.8668\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 0s 558us/step - loss: 0.3216 - accuracy: 0.8684\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 0s 544us/step - loss: 0.3210 - accuracy: 0.8664\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 0s 543us/step - loss: 0.3208 - accuracy: 0.8695\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 0s 559us/step - loss: 0.3212 - accuracy: 0.8659\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3209 - accuracy: 0.8661\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 0s 593us/step - loss: 0.3204 - accuracy: 0.8671\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 0s 521us/step - loss: 0.3212 - accuracy: 0.8684\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 0s 517us/step - loss: 0.3207 - accuracy: 0.8696\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 0s 546us/step - loss: 0.3205 - accuracy: 0.8666\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 0s 529us/step - loss: 0.3201 - accuracy: 0.8681\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 0s 564us/step - loss: 0.3208 - accuracy: 0.8669\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 0s 551us/step - loss: 0.3205 - accuracy: 0.8675\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3204 - accuracy: 0.8686\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 0s 555us/step - loss: 0.3203 - accuracy: 0.8677\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 0s 527us/step - loss: 0.3205 - accuracy: 0.8669\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 0s 515us/step - loss: 0.3202 - accuracy: 0.8679\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 0s 536us/step - loss: 0.3200 - accuracy: 0.8699\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 0s 534us/step - loss: 0.3197 - accuracy: 0.8694\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 0s 576us/step - loss: 0.3203 - accuracy: 0.8686\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 0s 559us/step - loss: 0.3199 - accuracy: 0.8666\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 0s 551us/step - loss: 0.3201 - accuracy: 0.8675\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 0s 532us/step - loss: 0.3197 - accuracy: 0.8705\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 0s 537us/step - loss: 0.3196 - accuracy: 0.8689\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 0s 550us/step - loss: 0.3195 - accuracy: 0.8687\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 0s 539us/step - loss: 0.3195 - accuracy: 0.8692\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 0s 536us/step - loss: 0.3191 - accuracy: 0.8696\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 0s 548us/step - loss: 0.3193 - accuracy: 0.8696\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 0s 566us/step - loss: 0.3196 - accuracy: 0.8692\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 0s 535us/step - loss: 0.3193 - accuracy: 0.8683\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3192 - accuracy: 0.8676\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 0s 541us/step - loss: 0.3198 - accuracy: 0.8679\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3193 - accuracy: 0.8677\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 0s 536us/step - loss: 0.3190 - accuracy: 0.8675\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 0s 560us/step - loss: 0.3193 - accuracy: 0.8696\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 0s 553us/step - loss: 0.3188 - accuracy: 0.8675\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 0s 564us/step - loss: 0.3195 - accuracy: 0.8665\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 0s 534us/step - loss: 0.3191 - accuracy: 0.8699\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 0s 523us/step - loss: 0.3190 - accuracy: 0.8679\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 0s 542us/step - loss: 0.3183 - accuracy: 0.8691\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 0s 539us/step - loss: 0.3189 - accuracy: 0.8684\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 0s 557us/step - loss: 0.3187 - accuracy: 0.8679\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 0s 530us/step - loss: 0.3183 - accuracy: 0.8690\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 0s 548us/step - loss: 0.3188 - accuracy: 0.86890s - loss: 0.3178 - accuracy: 0.86\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 0s 548us/step - loss: 0.3180 - accuracy: 0.8694\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 0s 529us/step - loss: 0.3186 - accuracy: 0.8681\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 0s 536us/step - loss: 0.3185 - accuracy: 0.8674\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 0s 535us/step - loss: 0.3189 - accuracy: 0.8683\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3184 - accuracy: 0.8674\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 0s 562us/step - loss: 0.3186 - accuracy: 0.8698\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 0s 559us/step - loss: 0.3182 - accuracy: 0.8687\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 0s 573us/step - loss: 0.3183 - accuracy: 0.8689\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 0s 564us/step - loss: 0.3181 - accuracy: 0.8695\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3184 - accuracy: 0.8668\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 0s 558us/step - loss: 0.3185 - accuracy: 0.8673\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 0s 560us/step - loss: 0.3182 - accuracy: 0.8685\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 0s 561us/step - loss: 0.3177 - accuracy: 0.8684\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 0s 558us/step - loss: 0.3177 - accuracy: 0.8685\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 0s 594us/step - loss: 0.3186 - accuracy: 0.8677\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 0s 539us/step - loss: 0.3179 - accuracy: 0.8681\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 0s 553us/step - loss: 0.3180 - accuracy: 0.8687\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 0s 568us/step - loss: 0.3177 - accuracy: 0.8692\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 0s 596us/step - loss: 0.3179 - accuracy: 0.8708\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 0s 590us/step - loss: 0.3185 - accuracy: 0.8671\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 0s 600us/step - loss: 0.3178 - accuracy: 0.8700\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 0s 608us/step - loss: 0.3175 - accuracy: 0.8692\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3173 - accuracy: 0.8690\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 0s 555us/step - loss: 0.3174 - accuracy: 0.8677\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 0s 548us/step - loss: 0.3177 - accuracy: 0.8683\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 0s 555us/step - loss: 0.3179 - accuracy: 0.8674\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 537us/step - loss: 0.3168 - accuracy: 0.8690\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 0s 577us/step - loss: 0.3179 - accuracy: 0.8685\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - 0s 549us/step - loss: 0.3173 - accuracy: 0.8686\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 0s 562us/step - loss: 0.3177 - accuracy: 0.8692\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.3173 - accuracy: 0.8695\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 0s 653us/step - loss: 0.3168 - accuracy: 0.8702\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 0s 599us/step - loss: 0.3176 - accuracy: 0.8694\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3172 - accuracy: 0.8679\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 0s 558us/step - loss: 0.3175 - accuracy: 0.8698\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 0s 604us/step - loss: 0.3174 - accuracy: 0.8681\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 0s 585us/step - loss: 0.3174 - accuracy: 0.8671\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 0s 553us/step - loss: 0.3171 - accuracy: 0.8683\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 0s 583us/step - loss: 0.3167 - accuracy: 0.8698\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 0s 593us/step - loss: 0.3170 - accuracy: 0.8695\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 0s 587us/step - loss: 0.3173 - accuracy: 0.8685\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 0s 548us/step - loss: 0.3168 - accuracy: 0.8686\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 0s 593us/step - loss: 0.3170 - accuracy: 0.8701\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 0s 554us/step - loss: 0.3168 - accuracy: 0.8695\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 0s 563us/step - loss: 0.3166 - accuracy: 0.8673\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 0s 562us/step - loss: 0.3170 - accuracy: 0.8677\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 0s 551us/step - loss: 0.3167 - accuracy: 0.8684\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 0s 548us/step - loss: 0.3169 - accuracy: 0.8708\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 0s 563us/step - loss: 0.3166 - accuracy: 0.8694\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 0s 549us/step - loss: 0.3167 - accuracy: 0.8680\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 0s 571us/step - loss: 0.3164 - accuracy: 0.8677\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 0s 548us/step - loss: 0.3160 - accuracy: 0.8711\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 0s 555us/step - loss: 0.3160 - accuracy: 0.8690\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 0s 551us/step - loss: 0.3167 - accuracy: 0.8684\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 0s 575us/step - loss: 0.3164 - accuracy: 0.8695\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 0s 551us/step - loss: 0.3165 - accuracy: 0.8699\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 0s 570us/step - loss: 0.3169 - accuracy: 0.8687\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - 0s 563us/step - loss: 0.3166 - accuracy: 0.8690\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 0s 534us/step - loss: 0.3164 - accuracy: 0.8692\n",
      "Epoch 190/200\n",
      "250/250 [==============================] - 0s 558us/step - loss: 0.3165 - accuracy: 0.8692\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 0s 573us/step - loss: 0.3171 - accuracy: 0.8686\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 0s 563us/step - loss: 0.3160 - accuracy: 0.8689\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 0s 562us/step - loss: 0.3162 - accuracy: 0.8700\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 0s 549us/step - loss: 0.3165 - accuracy: 0.8689\n",
      "Epoch 195/200\n",
      "250/250 [==============================] - 0s 557us/step - loss: 0.3169 - accuracy: 0.8689\n",
      "Epoch 196/200\n",
      "250/250 [==============================] - 0s 534us/step - loss: 0.3162 - accuracy: 0.8684\n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 0s 539us/step - loss: 0.3157 - accuracy: 0.8705\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 0s 547us/step - loss: 0.3159 - accuracy: 0.8694\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 0s 540us/step - loss: 0.3159 - accuracy: 0.8702\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 0s 534us/step - loss: 0.3164 - accuracy: 0.8679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f5c9c1b4f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x=X_train,y=y_train, batch_size=32, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(ann.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1505   90]\n",
      " [ 186  219]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.862"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann.predict_classes(X_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding early stop criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',patience=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Sequential()\n",
    "ann.add(Dense(12, activation = 'relu'))\n",
    "ann.add(Dense(6, activation = 'relu'))\n",
    "ann.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam', loss= 'binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.6607 - accuracy: 0.6236 - val_loss: 0.5169 - val_accuracy: 0.8000\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.4669 - accuracy: 0.8006 - val_loss: 0.4459 - val_accuracy: 0.8035\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4336 - accuracy: 0.8005 - val_loss: 0.4255 - val_accuracy: 0.8040\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.4214 - accuracy: 0.8058 - val_loss: 0.4151 - val_accuracy: 0.8075\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 0s 751us/step - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.4037 - val_accuracy: 0.8105\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 0s 705us/step - loss: 0.4014 - accuracy: 0.8124 - val_loss: 0.3914 - val_accuracy: 0.8160\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 0s 799us/step - loss: 0.3907 - accuracy: 0.8175 - val_loss: 0.3839 - val_accuracy: 0.8205\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 0s 701us/step - loss: 0.3824 - accuracy: 0.8183 - val_loss: 0.3749 - val_accuracy: 0.8240\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 0s 705us/step - loss: 0.3757 - accuracy: 0.8200 - val_loss: 0.3702 - val_accuracy: 0.8240\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 0s 796us/step - loss: 0.3702 - accuracy: 0.8213 - val_loss: 0.3649 - val_accuracy: 0.8235\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.3662 - accuracy: 0.8239 - val_loss: 0.3621 - val_accuracy: 0.8330\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.3619 - accuracy: 0.8374 - val_loss: 0.3581 - val_accuracy: 0.8430\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.3581 - accuracy: 0.8457 - val_loss: 0.3559 - val_accuracy: 0.8440\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.3548 - accuracy: 0.8508 - val_loss: 0.3519 - val_accuracy: 0.8495\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 0s 715us/step - loss: 0.3523 - accuracy: 0.8529 - val_loss: 0.3509 - val_accuracy: 0.8520\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.3505 - accuracy: 0.8543 - val_loss: 0.3521 - val_accuracy: 0.8565\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.3482 - accuracy: 0.8562 - val_loss: 0.3490 - val_accuracy: 0.8515\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.3466 - accuracy: 0.8579 - val_loss: 0.3494 - val_accuracy: 0.8535\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.3451 - accuracy: 0.8594 - val_loss: 0.3452 - val_accuracy: 0.8585\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 0s 736us/step - loss: 0.3434 - accuracy: 0.8602 - val_loss: 0.3435 - val_accuracy: 0.8545\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 0s 736us/step - loss: 0.3430 - accuracy: 0.8609 - val_loss: 0.3448 - val_accuracy: 0.8580\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.3415 - accuracy: 0.8618 - val_loss: 0.3454 - val_accuracy: 0.8530\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.3408 - accuracy: 0.8611 - val_loss: 0.3432 - val_accuracy: 0.8570\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 0s 742us/step - loss: 0.3403 - accuracy: 0.8624 - val_loss: 0.3441 - val_accuracy: 0.8540\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.3389 - accuracy: 0.8627 - val_loss: 0.3452 - val_accuracy: 0.8555\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.3386 - accuracy: 0.8645 - val_loss: 0.3429 - val_accuracy: 0.8545\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.3377 - accuracy: 0.8620 - val_loss: 0.3415 - val_accuracy: 0.8585\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.3383 - accuracy: 0.8637 - val_loss: 0.3450 - val_accuracy: 0.8545\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.3368 - accuracy: 0.8620 - val_loss: 0.3433 - val_accuracy: 0.8550\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 0s 699us/step - loss: 0.3367 - accuracy: 0.8622 - val_loss: 0.3458 - val_accuracy: 0.8550\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 0s 701us/step - loss: 0.3366 - accuracy: 0.8621 - val_loss: 0.3456 - val_accuracy: 0.8555\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.3358 - accuracy: 0.8648 - val_loss: 0.3436 - val_accuracy: 0.8580\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.3354 - accuracy: 0.8618 - val_loss: 0.3442 - val_accuracy: 0.8555\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 0s 781us/step - loss: 0.3347 - accuracy: 0.8639 - val_loss: 0.3422 - val_accuracy: 0.8565\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.3344 - accuracy: 0.8639 - val_loss: 0.3430 - val_accuracy: 0.8590\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.3339 - accuracy: 0.8636 - val_loss: 0.3413 - val_accuracy: 0.8580\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 0s 693us/step - loss: 0.3331 - accuracy: 0.8640 - val_loss: 0.3456 - val_accuracy: 0.8550\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 0s 715us/step - loss: 0.3334 - accuracy: 0.8648 - val_loss: 0.3405 - val_accuracy: 0.8565\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 0s 684us/step - loss: 0.3327 - accuracy: 0.8640 - val_loss: 0.3392 - val_accuracy: 0.8570\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.3322 - accuracy: 0.8652 - val_loss: 0.3380 - val_accuracy: 0.8570\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 0s 661us/step - loss: 0.3322 - accuracy: 0.8637 - val_loss: 0.3429 - val_accuracy: 0.8580\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 0s 737us/step - loss: 0.3314 - accuracy: 0.8645 - val_loss: 0.3408 - val_accuracy: 0.8565\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.3309 - accuracy: 0.8645 - val_loss: 0.3467 - val_accuracy: 0.8530\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 0s 721us/step - loss: 0.3307 - accuracy: 0.8649 - val_loss: 0.3403 - val_accuracy: 0.8565\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.3308 - accuracy: 0.8664 - val_loss: 0.3416 - val_accuracy: 0.8585\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.3307 - accuracy: 0.8645 - val_loss: 0.3415 - val_accuracy: 0.8600\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 0s 745us/step - loss: 0.3304 - accuracy: 0.8662 - val_loss: 0.3384 - val_accuracy: 0.8565\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.3298 - accuracy: 0.8662 - val_loss: 0.3415 - val_accuracy: 0.8610\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 0s 743us/step - loss: 0.3293 - accuracy: 0.8659 - val_loss: 0.3408 - val_accuracy: 0.8560\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 0s 743us/step - loss: 0.3295 - accuracy: 0.8655 - val_loss: 0.3414 - val_accuracy: 0.8575\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 0s 699us/step - loss: 0.3291 - accuracy: 0.8659 - val_loss: 0.3412 - val_accuracy: 0.8575\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 0s 677us/step - loss: 0.3288 - accuracy: 0.8645 - val_loss: 0.3436 - val_accuracy: 0.8555\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 0s 676us/step - loss: 0.3286 - accuracy: 0.8654 - val_loss: 0.3380 - val_accuracy: 0.8600\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 0s 742us/step - loss: 0.3283 - accuracy: 0.8660 - val_loss: 0.3395 - val_accuracy: 0.8575\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.3278 - accuracy: 0.8662 - val_loss: 0.3417 - val_accuracy: 0.8570\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 0s 728us/step - loss: 0.3275 - accuracy: 0.8664 - val_loss: 0.3414 - val_accuracy: 0.8575\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 699us/step - loss: 0.3274 - accuracy: 0.8669 - val_loss: 0.3408 - val_accuracy: 0.8535\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 0s 735us/step - loss: 0.3273 - accuracy: 0.8664 - val_loss: 0.3404 - val_accuracy: 0.8605\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.3275 - accuracy: 0.8666 - val_loss: 0.3410 - val_accuracy: 0.8560\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 0s 703us/step - loss: 0.3266 - accuracy: 0.8683 - val_loss: 0.3383 - val_accuracy: 0.8575\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 0s 721us/step - loss: 0.3271 - accuracy: 0.8680 - val_loss: 0.3392 - val_accuracy: 0.8585\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 0s 899us/step - loss: 0.3266 - accuracy: 0.8681 - val_loss: 0.3397 - val_accuracy: 0.8580\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 0s 764us/step - loss: 0.3263 - accuracy: 0.8670 - val_loss: 0.3400 - val_accuracy: 0.8555\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 0s 817us/step - loss: 0.3262 - accuracy: 0.8671 - val_loss: 0.3387 - val_accuracy: 0.8585\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 0s 820us/step - loss: 0.3263 - accuracy: 0.8679 - val_loss: 0.3388 - val_accuracy: 0.8565\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 0s 700us/step - loss: 0.3263 - accuracy: 0.8668 - val_loss: 0.3415 - val_accuracy: 0.8570\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.3256 - accuracy: 0.8683 - val_loss: 0.3392 - val_accuracy: 0.8575\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.3254 - accuracy: 0.8690 - val_loss: 0.3382 - val_accuracy: 0.8565\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 0s 729us/step - loss: 0.3253 - accuracy: 0.8669 - val_loss: 0.3383 - val_accuracy: 0.8600\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 0s 725us/step - loss: 0.3248 - accuracy: 0.8677 - val_loss: 0.3425 - val_accuracy: 0.8540\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 0s 803us/step - loss: 0.3248 - accuracy: 0.8677 - val_loss: 0.3403 - val_accuracy: 0.8575\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 0s 697us/step - loss: 0.3247 - accuracy: 0.8679 - val_loss: 0.3377 - val_accuracy: 0.8595\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 0s 723us/step - loss: 0.3243 - accuracy: 0.8680 - val_loss: 0.3377 - val_accuracy: 0.8630\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.3250 - accuracy: 0.8687 - val_loss: 0.3406 - val_accuracy: 0.8550\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 0s 741us/step - loss: 0.3245 - accuracy: 0.8700 - val_loss: 0.3389 - val_accuracy: 0.8560\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.3245 - accuracy: 0.8676 - val_loss: 0.3389 - val_accuracy: 0.8600\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.3244 - accuracy: 0.8673 - val_loss: 0.3374 - val_accuracy: 0.8570\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 0s 755us/step - loss: 0.3241 - accuracy: 0.8687 - val_loss: 0.3384 - val_accuracy: 0.8570\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 0s 745us/step - loss: 0.3241 - accuracy: 0.8700 - val_loss: 0.3393 - val_accuracy: 0.8600\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 0s 684us/step - loss: 0.3239 - accuracy: 0.8661 - val_loss: 0.3378 - val_accuracy: 0.8565\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.3236 - accuracy: 0.8686 - val_loss: 0.3376 - val_accuracy: 0.8610\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 0s 679us/step - loss: 0.3239 - accuracy: 0.8674 - val_loss: 0.3388 - val_accuracy: 0.8585\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.3238 - accuracy: 0.8686 - val_loss: 0.3371 - val_accuracy: 0.8595\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.3234 - accuracy: 0.8677 - val_loss: 0.3413 - val_accuracy: 0.8510\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.3237 - accuracy: 0.8681 - val_loss: 0.3392 - val_accuracy: 0.8545\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 0s 697us/step - loss: 0.3236 - accuracy: 0.8676 - val_loss: 0.3378 - val_accuracy: 0.8605\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.3231 - accuracy: 0.8675 - val_loss: 0.3368 - val_accuracy: 0.8585\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.3233 - accuracy: 0.8677 - val_loss: 0.3408 - val_accuracy: 0.8550\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.3228 - accuracy: 0.8684 - val_loss: 0.3363 - val_accuracy: 0.8560\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 0s 764us/step - loss: 0.3231 - accuracy: 0.8670 - val_loss: 0.3433 - val_accuracy: 0.8530\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.3233 - accuracy: 0.8681 - val_loss: 0.3373 - val_accuracy: 0.8570\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 0s 773us/step - loss: 0.3229 - accuracy: 0.8691 - val_loss: 0.3383 - val_accuracy: 0.8570\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 0s 693us/step - loss: 0.3230 - accuracy: 0.8683 - val_loss: 0.3383 - val_accuracy: 0.8580\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.3223 - accuracy: 0.8686 - val_loss: 0.3391 - val_accuracy: 0.8535\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 0s 761us/step - loss: 0.3228 - accuracy: 0.8684 - val_loss: 0.3385 - val_accuracy: 0.8555\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.3229 - accuracy: 0.8687 - val_loss: 0.3389 - val_accuracy: 0.8545\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 0s 782us/step - loss: 0.3224 - accuracy: 0.8691 - val_loss: 0.3391 - val_accuracy: 0.8545\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.3223 - accuracy: 0.8704 - val_loss: 0.3374 - val_accuracy: 0.8555\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 0s 750us/step - loss: 0.3223 - accuracy: 0.8686 - val_loss: 0.3386 - val_accuracy: 0.8540\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.3217 - accuracy: 0.8691 - val_loss: 0.3405 - val_accuracy: 0.8555\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.3219 - accuracy: 0.8687 - val_loss: 0.3409 - val_accuracy: 0.8550\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 0s 699us/step - loss: 0.3225 - accuracy: 0.8683 - val_loss: 0.3395 - val_accuracy: 0.8530\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 0s 743us/step - loss: 0.3216 - accuracy: 0.8691 - val_loss: 0.3385 - val_accuracy: 0.8590\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 0s 701us/step - loss: 0.3220 - accuracy: 0.8691 - val_loss: 0.3406 - val_accuracy: 0.8575\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.3221 - accuracy: 0.8699 - val_loss: 0.3389 - val_accuracy: 0.8530\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 0s 679us/step - loss: 0.3220 - accuracy: 0.8689 - val_loss: 0.3413 - val_accuracy: 0.8495\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.3214 - accuracy: 0.8706 - val_loss: 0.3417 - val_accuracy: 0.8545\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.3218 - accuracy: 0.8684 - val_loss: 0.3394 - val_accuracy: 0.8550\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.3217 - accuracy: 0.8704 - val_loss: 0.3384 - val_accuracy: 0.8555\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.3213 - accuracy: 0.8698 - val_loss: 0.3372 - val_accuracy: 0.8565\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.3213 - accuracy: 0.8700 - val_loss: 0.3375 - val_accuracy: 0.8555\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.3216 - accuracy: 0.8694 - val_loss: 0.3378 - val_accuracy: 0.8570\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 711us/step - loss: 0.3214 - accuracy: 0.8709 - val_loss: 0.3373 - val_accuracy: 0.8555\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 0s 732us/step - loss: 0.3211 - accuracy: 0.8685 - val_loss: 0.3392 - val_accuracy: 0.8555\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.3211 - accuracy: 0.8717 - val_loss: 0.3424 - val_accuracy: 0.8505\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 0s 675us/step - loss: 0.3214 - accuracy: 0.8695 - val_loss: 0.3411 - val_accuracy: 0.8515\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 0s 693us/step - loss: 0.3215 - accuracy: 0.8714 - val_loss: 0.3392 - val_accuracy: 0.8555\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.3210 - accuracy: 0.8690 - val_loss: 0.3396 - val_accuracy: 0.8515\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.3208 - accuracy: 0.8698 - val_loss: 0.3385 - val_accuracy: 0.8530\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.3214 - accuracy: 0.8692 - val_loss: 0.3406 - val_accuracy: 0.8510\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.3210 - accuracy: 0.8715 - val_loss: 0.3389 - val_accuracy: 0.8515\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.3214 - accuracy: 0.8714 - val_loss: 0.3393 - val_accuracy: 0.8535\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.3209 - accuracy: 0.8717 - val_loss: 0.3381 - val_accuracy: 0.8540\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.3208 - accuracy: 0.8702 - val_loss: 0.3416 - val_accuracy: 0.8515\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 0s 671us/step - loss: 0.3203 - accuracy: 0.8714 - val_loss: 0.3420 - val_accuracy: 0.8500\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 0s 676us/step - loss: 0.3205 - accuracy: 0.8691 - val_loss: 0.3392 - val_accuracy: 0.8560\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 0s 675us/step - loss: 0.3211 - accuracy: 0.8712 - val_loss: 0.3413 - val_accuracy: 0.8490\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.3212 - accuracy: 0.8705 - val_loss: 0.3402 - val_accuracy: 0.8520\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 0s 676us/step - loss: 0.3203 - accuracy: 0.8708 - val_loss: 0.3390 - val_accuracy: 0.8565\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 0s 679us/step - loss: 0.3206 - accuracy: 0.8709 - val_loss: 0.3390 - val_accuracy: 0.8530\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.3207 - accuracy: 0.8704 - val_loss: 0.3380 - val_accuracy: 0.8540\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 0s 754us/step - loss: 0.3203 - accuracy: 0.8702 - val_loss: 0.3400 - val_accuracy: 0.8525\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 0s 699us/step - loss: 0.3204 - accuracy: 0.8717 - val_loss: 0.3420 - val_accuracy: 0.8475\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.3206 - accuracy: 0.8716 - val_loss: 0.3427 - val_accuracy: 0.8520\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.3203 - accuracy: 0.8721 - val_loss: 0.3390 - val_accuracy: 0.8530\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.3204 - accuracy: 0.8716 - val_loss: 0.3406 - val_accuracy: 0.8525\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 0s 743us/step - loss: 0.3202 - accuracy: 0.8709 - val_loss: 0.3414 - val_accuracy: 0.8505\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.3201 - accuracy: 0.8692 - val_loss: 0.3380 - val_accuracy: 0.8535\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.3202 - accuracy: 0.8715 - val_loss: 0.3406 - val_accuracy: 0.8530\n",
      "Epoch 00139: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f5d5274670>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x=X_train,y=y_train, batch_size=32, epochs=200, verbose=1, callbacks=[early_stop], validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(ann.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1504   91]\n",
      " [ 203  202]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.853"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann.predict_classes(X_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding dropout layers\n",
    "ann = Sequential()\n",
    "ann.add(Dense(12, activation = 'relu'))\n",
    "ann.add(Dropout(0.5))\n",
    "ann.add(Dense(6, activation = 'relu'))\n",
    "ann.add(Dropout(0.5))\n",
    "ann.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.8382 - accuracy: 0.5290 - val_loss: 0.6410 - val_accuracy: 0.7730\n",
      "Epoch 2/600\n",
      "250/250 [==============================] - 0s 785us/step - loss: 0.6286 - accuracy: 0.7579 - val_loss: 0.5802 - val_accuracy: 0.7975\n",
      "Epoch 3/600\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.5656 - accuracy: 0.7900 - val_loss: 0.5311 - val_accuracy: 0.7975\n",
      "Epoch 4/600\n",
      "250/250 [==============================] - 0s 729us/step - loss: 0.5335 - accuracy: 0.7970 - val_loss: 0.5054 - val_accuracy: 0.7975\n",
      "Epoch 5/600\n",
      "250/250 [==============================] - 0s 751us/step - loss: 0.5174 - accuracy: 0.7996 - val_loss: 0.4896 - val_accuracy: 0.7975\n",
      "Epoch 6/600\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.4952 - accuracy: 0.8004 - val_loss: 0.4733 - val_accuracy: 0.7975\n",
      "Epoch 7/600\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.4883 - accuracy: 0.8036 - val_loss: 0.4635 - val_accuracy: 0.7975\n",
      "Epoch 8/600\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.4850 - accuracy: 0.7981 - val_loss: 0.4553 - val_accuracy: 0.7975\n",
      "Epoch 9/600\n",
      "250/250 [==============================] - 0s 766us/step - loss: 0.4753 - accuracy: 0.8043 - val_loss: 0.4473 - val_accuracy: 0.7975\n",
      "Epoch 10/600\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.4672 - accuracy: 0.8061 - val_loss: 0.4371 - val_accuracy: 0.8000\n",
      "Epoch 11/600\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.4587 - accuracy: 0.8081 - val_loss: 0.4266 - val_accuracy: 0.8030\n",
      "Epoch 12/600\n",
      "250/250 [==============================] - 0s 724us/step - loss: 0.4552 - accuracy: 0.8083 - val_loss: 0.4235 - val_accuracy: 0.8065\n",
      "Epoch 13/600\n",
      "250/250 [==============================] - 0s 745us/step - loss: 0.4476 - accuracy: 0.8150 - val_loss: 0.4192 - val_accuracy: 0.8080\n",
      "Epoch 14/600\n",
      "250/250 [==============================] - 0s 720us/step - loss: 0.4452 - accuracy: 0.8146 - val_loss: 0.4130 - val_accuracy: 0.8115\n",
      "Epoch 15/600\n",
      "250/250 [==============================] - 0s 728us/step - loss: 0.4457 - accuracy: 0.8159 - val_loss: 0.4111 - val_accuracy: 0.8140\n",
      "Epoch 16/600\n",
      "250/250 [==============================] - 0s 739us/step - loss: 0.4410 - accuracy: 0.8170 - val_loss: 0.4078 - val_accuracy: 0.8155\n",
      "Epoch 17/600\n",
      "250/250 [==============================] - 0s 725us/step - loss: 0.4402 - accuracy: 0.8175 - val_loss: 0.4061 - val_accuracy: 0.8145\n",
      "Epoch 18/600\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.4454 - accuracy: 0.8150 - val_loss: 0.4089 - val_accuracy: 0.8155\n",
      "Epoch 19/600\n",
      "250/250 [==============================] - 0s 742us/step - loss: 0.4387 - accuracy: 0.8180 - val_loss: 0.4089 - val_accuracy: 0.8140\n",
      "Epoch 20/600\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.4332 - accuracy: 0.8185 - val_loss: 0.4049 - val_accuracy: 0.8170\n",
      "Epoch 21/600\n",
      "250/250 [==============================] - 0s 705us/step - loss: 0.4407 - accuracy: 0.8140 - val_loss: 0.4050 - val_accuracy: 0.8185\n",
      "Epoch 22/600\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.4333 - accuracy: 0.8198 - val_loss: 0.4019 - val_accuracy: 0.8195\n",
      "Epoch 23/600\n",
      "250/250 [==============================] - 0s 723us/step - loss: 0.4325 - accuracy: 0.8183 - val_loss: 0.4005 - val_accuracy: 0.8175\n",
      "Epoch 24/600\n",
      "250/250 [==============================] - 0s 742us/step - loss: 0.4353 - accuracy: 0.8154 - val_loss: 0.4008 - val_accuracy: 0.8200\n",
      "Epoch 25/600\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.4348 - accuracy: 0.8192 - val_loss: 0.3959 - val_accuracy: 0.8225\n",
      "Epoch 26/600\n",
      "250/250 [==============================] - 0s 768us/step - loss: 0.4296 - accuracy: 0.8175 - val_loss: 0.3932 - val_accuracy: 0.8215\n",
      "Epoch 27/600\n",
      "250/250 [==============================] - 0s 729us/step - loss: 0.4364 - accuracy: 0.8170 - val_loss: 0.3993 - val_accuracy: 0.8205\n",
      "Epoch 28/600\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.4299 - accuracy: 0.8196 - val_loss: 0.3927 - val_accuracy: 0.8225\n",
      "Epoch 29/600\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.4292 - accuracy: 0.8174 - val_loss: 0.3920 - val_accuracy: 0.8230\n",
      "Epoch 30/600\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.4318 - accuracy: 0.8201 - val_loss: 0.3941 - val_accuracy: 0.8220\n",
      "Epoch 31/600\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.4339 - accuracy: 0.8165 - val_loss: 0.3942 - val_accuracy: 0.8225\n",
      "Epoch 32/600\n",
      "250/250 [==============================] - 0s 724us/step - loss: 0.4265 - accuracy: 0.8216 - val_loss: 0.3899 - val_accuracy: 0.8230\n",
      "Epoch 33/600\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.4299 - accuracy: 0.8210 - val_loss: 0.3908 - val_accuracy: 0.8220\n",
      "Epoch 34/600\n",
      "250/250 [==============================] - 0s 739us/step - loss: 0.4225 - accuracy: 0.8229 - val_loss: 0.3906 - val_accuracy: 0.8200\n",
      "Epoch 35/600\n",
      "250/250 [==============================] - 0s 715us/step - loss: 0.4267 - accuracy: 0.8259 - val_loss: 0.3881 - val_accuracy: 0.8225\n",
      "Epoch 36/600\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.4243 - accuracy: 0.8230 - val_loss: 0.3845 - val_accuracy: 0.8255\n",
      "Epoch 37/600\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.4260 - accuracy: 0.8221 - val_loss: 0.3893 - val_accuracy: 0.8215\n",
      "Epoch 38/600\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.4292 - accuracy: 0.8206 - val_loss: 0.3839 - val_accuracy: 0.8230\n",
      "Epoch 39/600\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.4229 - accuracy: 0.8241 - val_loss: 0.3819 - val_accuracy: 0.8265\n",
      "Epoch 40/600\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.4196 - accuracy: 0.8234 - val_loss: 0.3813 - val_accuracy: 0.8260\n",
      "Epoch 41/600\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.4261 - accuracy: 0.8224 - val_loss: 0.3851 - val_accuracy: 0.8220\n",
      "Epoch 42/600\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.4250 - accuracy: 0.8213 - val_loss: 0.3866 - val_accuracy: 0.8225\n",
      "Epoch 43/600\n",
      "250/250 [==============================] - 0s 729us/step - loss: 0.4282 - accuracy: 0.8225 - val_loss: 0.3821 - val_accuracy: 0.8250\n",
      "Epoch 44/600\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.4202 - accuracy: 0.8250 - val_loss: 0.3839 - val_accuracy: 0.8220\n",
      "Epoch 45/600\n",
      "250/250 [==============================] - 0s 692us/step - loss: 0.4179 - accuracy: 0.8266 - val_loss: 0.3833 - val_accuracy: 0.8225\n",
      "Epoch 46/600\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.4199 - accuracy: 0.8261 - val_loss: 0.3760 - val_accuracy: 0.8335\n",
      "Epoch 47/600\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.4202 - accuracy: 0.8234 - val_loss: 0.3807 - val_accuracy: 0.8245\n",
      "Epoch 48/600\n",
      "250/250 [==============================] - 0s 668us/step - loss: 0.4179 - accuracy: 0.8280 - val_loss: 0.3742 - val_accuracy: 0.8340\n",
      "Epoch 49/600\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.4221 - accuracy: 0.8213 - val_loss: 0.3796 - val_accuracy: 0.8260\n",
      "Epoch 50/600\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.4224 - accuracy: 0.8246 - val_loss: 0.3814 - val_accuracy: 0.8230\n",
      "Epoch 51/600\n",
      "250/250 [==============================] - 0s 719us/step - loss: 0.4224 - accuracy: 0.8221 - val_loss: 0.3795 - val_accuracy: 0.8235\n",
      "Epoch 52/600\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.4213 - accuracy: 0.8244 - val_loss: 0.3778 - val_accuracy: 0.8275\n",
      "Epoch 53/600\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.4211 - accuracy: 0.8238 - val_loss: 0.3777 - val_accuracy: 0.8315\n",
      "Epoch 54/600\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.4160 - accuracy: 0.8304 - val_loss: 0.3750 - val_accuracy: 0.8355\n",
      "Epoch 55/600\n",
      "250/250 [==============================] - 0s 700us/step - loss: 0.4190 - accuracy: 0.8273 - val_loss: 0.3722 - val_accuracy: 0.8365\n",
      "Epoch 56/600\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.4173 - accuracy: 0.8259 - val_loss: 0.3766 - val_accuracy: 0.8295\n",
      "Epoch 57/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 726us/step - loss: 0.4145 - accuracy: 0.8286 - val_loss: 0.3739 - val_accuracy: 0.8345\n",
      "Epoch 58/600\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.4189 - accuracy: 0.8274 - val_loss: 0.3753 - val_accuracy: 0.8315\n",
      "Epoch 59/600\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.4213 - accuracy: 0.8255 - val_loss: 0.3740 - val_accuracy: 0.8335\n",
      "Epoch 60/600\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.4159 - accuracy: 0.8274 - val_loss: 0.3706 - val_accuracy: 0.8380\n",
      "Epoch 61/600\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.4197 - accuracy: 0.8289 - val_loss: 0.3756 - val_accuracy: 0.8315\n",
      "Epoch 62/600\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.4188 - accuracy: 0.8265 - val_loss: 0.3733 - val_accuracy: 0.8335\n",
      "Epoch 63/600\n",
      "250/250 [==============================] - 0s 727us/step - loss: 0.4206 - accuracy: 0.8259 - val_loss: 0.3738 - val_accuracy: 0.8325\n",
      "Epoch 64/600\n",
      "250/250 [==============================] - 0s 685us/step - loss: 0.4157 - accuracy: 0.8276 - val_loss: 0.3712 - val_accuracy: 0.8375\n",
      "Epoch 65/600\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.4152 - accuracy: 0.8289 - val_loss: 0.3735 - val_accuracy: 0.8300\n",
      "Epoch 66/600\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.4163 - accuracy: 0.8313 - val_loss: 0.3679 - val_accuracy: 0.8470\n",
      "Epoch 67/600\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.4148 - accuracy: 0.8322 - val_loss: 0.3700 - val_accuracy: 0.8395\n",
      "Epoch 68/600\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.4104 - accuracy: 0.8314 - val_loss: 0.3659 - val_accuracy: 0.8455\n",
      "Epoch 69/600\n",
      "250/250 [==============================] - 0s 734us/step - loss: 0.4134 - accuracy: 0.8319 - val_loss: 0.3703 - val_accuracy: 0.8355\n",
      "Epoch 70/600\n",
      "250/250 [==============================] - 0s 708us/step - loss: 0.4227 - accuracy: 0.8265 - val_loss: 0.3755 - val_accuracy: 0.8270\n",
      "Epoch 71/600\n",
      "250/250 [==============================] - 0s 703us/step - loss: 0.4192 - accuracy: 0.8275 - val_loss: 0.3720 - val_accuracy: 0.8325\n",
      "Epoch 72/600\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.4184 - accuracy: 0.8284 - val_loss: 0.3723 - val_accuracy: 0.8335\n",
      "Epoch 73/600\n",
      "250/250 [==============================] - 0s 699us/step - loss: 0.4111 - accuracy: 0.8271 - val_loss: 0.3707 - val_accuracy: 0.8355\n",
      "Epoch 74/600\n",
      "250/250 [==============================] - 0s 677us/step - loss: 0.4181 - accuracy: 0.8280 - val_loss: 0.3710 - val_accuracy: 0.8325\n",
      "Epoch 75/600\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.4144 - accuracy: 0.8273 - val_loss: 0.3693 - val_accuracy: 0.8330\n",
      "Epoch 76/600\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.4106 - accuracy: 0.8300 - val_loss: 0.3688 - val_accuracy: 0.8355\n",
      "Epoch 77/600\n",
      "250/250 [==============================] - 0s 697us/step - loss: 0.4140 - accuracy: 0.8316 - val_loss: 0.3696 - val_accuracy: 0.8330\n",
      "Epoch 78/600\n",
      "250/250 [==============================] - 0s 692us/step - loss: 0.4139 - accuracy: 0.8281 - val_loss: 0.3658 - val_accuracy: 0.8445\n",
      "Epoch 79/600\n",
      "250/250 [==============================] - 0s 684us/step - loss: 0.4167 - accuracy: 0.8276 - val_loss: 0.3675 - val_accuracy: 0.8420\n",
      "Epoch 80/600\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.4165 - accuracy: 0.8286 - val_loss: 0.3659 - val_accuracy: 0.8405\n",
      "Epoch 81/600\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.4193 - accuracy: 0.8280 - val_loss: 0.3705 - val_accuracy: 0.8315\n",
      "Epoch 82/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4170 - accuracy: 0.8253 - val_loss: 0.3675 - val_accuracy: 0.8360\n",
      "Epoch 83/600\n",
      "250/250 [==============================] - 0s 677us/step - loss: 0.4132 - accuracy: 0.8284 - val_loss: 0.3648 - val_accuracy: 0.8450\n",
      "Epoch 84/600\n",
      "250/250 [==============================] - 0s 679us/step - loss: 0.4174 - accuracy: 0.8274 - val_loss: 0.3651 - val_accuracy: 0.8430\n",
      "Epoch 85/600\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.4136 - accuracy: 0.8285 - val_loss: 0.3673 - val_accuracy: 0.8395\n",
      "Epoch 86/600\n",
      "250/250 [==============================] - 0s 789us/step - loss: 0.4142 - accuracy: 0.8304 - val_loss: 0.3693 - val_accuracy: 0.8360\n",
      "Epoch 87/600\n",
      "250/250 [==============================] - 0s 821us/step - loss: 0.4133 - accuracy: 0.8284 - val_loss: 0.3714 - val_accuracy: 0.8300\n",
      "Epoch 88/600\n",
      "250/250 [==============================] - 0s 745us/step - loss: 0.4130 - accuracy: 0.8300 - val_loss: 0.3670 - val_accuracy: 0.8370\n",
      "Epoch 89/600\n",
      "250/250 [==============================] - 0s 837us/step - loss: 0.4115 - accuracy: 0.8289 - val_loss: 0.3641 - val_accuracy: 0.8460\n",
      "Epoch 90/600\n",
      "250/250 [==============================] - 0s 752us/step - loss: 0.4158 - accuracy: 0.8285 - val_loss: 0.3646 - val_accuracy: 0.8425\n",
      "Epoch 91/600\n",
      "250/250 [==============================] - 0s 781us/step - loss: 0.4139 - accuracy: 0.8294 - val_loss: 0.3628 - val_accuracy: 0.8465\n",
      "Epoch 92/600\n",
      "250/250 [==============================] - 0s 741us/step - loss: 0.4147 - accuracy: 0.8269 - val_loss: 0.3638 - val_accuracy: 0.8450\n",
      "Epoch 93/600\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.4139 - accuracy: 0.8251 - val_loss: 0.3668 - val_accuracy: 0.8380\n",
      "Epoch 94/600\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.4163 - accuracy: 0.8269 - val_loss: 0.3679 - val_accuracy: 0.8335\n",
      "Epoch 95/600\n",
      "250/250 [==============================] - 0s 737us/step - loss: 0.4111 - accuracy: 0.8304 - val_loss: 0.3663 - val_accuracy: 0.8360\n",
      "Epoch 96/600\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.4140 - accuracy: 0.8281 - val_loss: 0.3640 - val_accuracy: 0.8475\n",
      "Epoch 97/600\n",
      "250/250 [==============================] - 0s 708us/step - loss: 0.4087 - accuracy: 0.8342 - val_loss: 0.3659 - val_accuracy: 0.8420\n",
      "Epoch 98/600\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.4072 - accuracy: 0.8342 - val_loss: 0.3655 - val_accuracy: 0.8440\n",
      "Epoch 99/600\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.4078 - accuracy: 0.8351 - val_loss: 0.3624 - val_accuracy: 0.8510\n",
      "Epoch 100/600\n",
      "250/250 [==============================] - 0s 721us/step - loss: 0.4117 - accuracy: 0.8307 - val_loss: 0.3610 - val_accuracy: 0.8500\n",
      "Epoch 101/600\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.4214 - accuracy: 0.8290 - val_loss: 0.3668 - val_accuracy: 0.8370\n",
      "Epoch 102/600\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.4130 - accuracy: 0.8299 - val_loss: 0.3663 - val_accuracy: 0.8370\n",
      "Epoch 103/600\n",
      "250/250 [==============================] - 0s 810us/step - loss: 0.4168 - accuracy: 0.8254 - val_loss: 0.3665 - val_accuracy: 0.8365\n",
      "Epoch 104/600\n",
      "250/250 [==============================] - 0s 741us/step - loss: 0.4078 - accuracy: 0.8299 - val_loss: 0.3645 - val_accuracy: 0.8405\n",
      "Epoch 105/600\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.4152 - accuracy: 0.8310 - val_loss: 0.3626 - val_accuracy: 0.8475\n",
      "Epoch 106/600\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.4131 - accuracy: 0.8310 - val_loss: 0.3666 - val_accuracy: 0.8370\n",
      "Epoch 107/600\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.4106 - accuracy: 0.8295 - val_loss: 0.3636 - val_accuracy: 0.8390\n",
      "Epoch 108/600\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.4104 - accuracy: 0.8311 - val_loss: 0.3647 - val_accuracy: 0.8405\n",
      "Epoch 109/600\n",
      "250/250 [==============================] - 0s 727us/step - loss: 0.4102 - accuracy: 0.8301 - val_loss: 0.3664 - val_accuracy: 0.8300\n",
      "Epoch 110/600\n",
      "250/250 [==============================] - 0s 719us/step - loss: 0.4127 - accuracy: 0.8320 - val_loss: 0.3671 - val_accuracy: 0.8345\n",
      "Epoch 111/600\n",
      "250/250 [==============================] - 0s 727us/step - loss: 0.4127 - accuracy: 0.8280 - val_loss: 0.3648 - val_accuracy: 0.8430\n",
      "Epoch 112/600\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.4084 - accuracy: 0.8336 - val_loss: 0.3620 - val_accuracy: 0.8470\n",
      "Epoch 113/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 690us/step - loss: 0.4107 - accuracy: 0.8291 - val_loss: 0.3627 - val_accuracy: 0.8480\n",
      "Epoch 114/600\n",
      "250/250 [==============================] - 0s 693us/step - loss: 0.4104 - accuracy: 0.8282 - val_loss: 0.3612 - val_accuracy: 0.8480\n",
      "Epoch 115/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4178 - accuracy: 0.8266 - val_loss: 0.3640 - val_accuracy: 0.8405\n",
      "Epoch 116/600\n",
      "250/250 [==============================] - 0s 713us/step - loss: 0.4138 - accuracy: 0.8300 - val_loss: 0.3647 - val_accuracy: 0.8400\n",
      "Epoch 117/600\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.4080 - accuracy: 0.8353 - val_loss: 0.3632 - val_accuracy: 0.8405\n",
      "Epoch 118/600\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.4095 - accuracy: 0.8314 - val_loss: 0.3599 - val_accuracy: 0.8495\n",
      "Epoch 119/600\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.4152 - accuracy: 0.8307 - val_loss: 0.3645 - val_accuracy: 0.8440\n",
      "Epoch 120/600\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.4100 - accuracy: 0.8322 - val_loss: 0.3636 - val_accuracy: 0.8395\n",
      "Epoch 121/600\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.4082 - accuracy: 0.8350 - val_loss: 0.3660 - val_accuracy: 0.8355\n",
      "Epoch 122/600\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.4177 - accuracy: 0.8244 - val_loss: 0.3675 - val_accuracy: 0.8360\n",
      "Epoch 123/600\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.4141 - accuracy: 0.8278 - val_loss: 0.3676 - val_accuracy: 0.8350\n",
      "Epoch 124/600\n",
      "250/250 [==============================] - 0s 703us/step - loss: 0.4110 - accuracy: 0.8307 - val_loss: 0.3637 - val_accuracy: 0.8430\n",
      "Epoch 125/600\n",
      "250/250 [==============================] - 0s 700us/step - loss: 0.4089 - accuracy: 0.8284 - val_loss: 0.3600 - val_accuracy: 0.8515\n",
      "Epoch 126/600\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.4101 - accuracy: 0.8296 - val_loss: 0.3620 - val_accuracy: 0.8400\n",
      "Epoch 127/600\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.4165 - accuracy: 0.8306 - val_loss: 0.3642 - val_accuracy: 0.8390\n",
      "Epoch 128/600\n",
      "250/250 [==============================] - 0s 725us/step - loss: 0.4030 - accuracy: 0.8336 - val_loss: 0.3609 - val_accuracy: 0.8445\n",
      "Epoch 129/600\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.4123 - accuracy: 0.8310 - val_loss: 0.3601 - val_accuracy: 0.8480\n",
      "Epoch 130/600\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.4105 - accuracy: 0.8320 - val_loss: 0.3609 - val_accuracy: 0.8510\n",
      "Epoch 131/600\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.4127 - accuracy: 0.8353 - val_loss: 0.3648 - val_accuracy: 0.8405\n",
      "Epoch 132/600\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.4065 - accuracy: 0.8332 - val_loss: 0.3607 - val_accuracy: 0.8490\n",
      "Epoch 133/600\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.4063 - accuracy: 0.8316 - val_loss: 0.3619 - val_accuracy: 0.8430\n",
      "Epoch 134/600\n",
      "250/250 [==============================] - 0s 724us/step - loss: 0.4100 - accuracy: 0.8317 - val_loss: 0.3600 - val_accuracy: 0.8435\n",
      "Epoch 135/600\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.4097 - accuracy: 0.8295 - val_loss: 0.3615 - val_accuracy: 0.8445\n",
      "Epoch 136/600\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.4099 - accuracy: 0.8279 - val_loss: 0.3616 - val_accuracy: 0.8410\n",
      "Epoch 137/600\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.4160 - accuracy: 0.8298 - val_loss: 0.3643 - val_accuracy: 0.8390\n",
      "Epoch 138/600\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.4155 - accuracy: 0.8284 - val_loss: 0.3637 - val_accuracy: 0.8430\n",
      "Epoch 139/600\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.4067 - accuracy: 0.8316 - val_loss: 0.3605 - val_accuracy: 0.8420\n",
      "Epoch 140/600\n",
      "250/250 [==============================] - 0s 664us/step - loss: 0.4131 - accuracy: 0.8307 - val_loss: 0.3619 - val_accuracy: 0.8415\n",
      "Epoch 141/600\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.4095 - accuracy: 0.8338 - val_loss: 0.3592 - val_accuracy: 0.8505\n",
      "Epoch 142/600\n",
      "250/250 [==============================] - 0s 717us/step - loss: 0.4113 - accuracy: 0.8299 - val_loss: 0.3620 - val_accuracy: 0.8435\n",
      "Epoch 143/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4123 - accuracy: 0.8294 - val_loss: 0.3611 - val_accuracy: 0.8500\n",
      "Epoch 144/600\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.4134 - accuracy: 0.8292 - val_loss: 0.3623 - val_accuracy: 0.8460\n",
      "Epoch 145/600\n",
      "250/250 [==============================] - 0s 717us/step - loss: 0.4122 - accuracy: 0.8298 - val_loss: 0.3645 - val_accuracy: 0.8385\n",
      "Epoch 146/600\n",
      "250/250 [==============================] - 0s 700us/step - loss: 0.4125 - accuracy: 0.8282 - val_loss: 0.3618 - val_accuracy: 0.8485\n",
      "Epoch 147/600\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.4027 - accuracy: 0.8351 - val_loss: 0.3561 - val_accuracy: 0.8545\n",
      "Epoch 148/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4072 - accuracy: 0.8325 - val_loss: 0.3617 - val_accuracy: 0.8430\n",
      "Epoch 149/600\n",
      "250/250 [==============================] - 0s 735us/step - loss: 0.4118 - accuracy: 0.8310 - val_loss: 0.3627 - val_accuracy: 0.8425\n",
      "Epoch 150/600\n",
      "250/250 [==============================] - 0s 685us/step - loss: 0.4084 - accuracy: 0.8309 - val_loss: 0.3583 - val_accuracy: 0.8510\n",
      "Epoch 151/600\n",
      "250/250 [==============================] - 0s 736us/step - loss: 0.4101 - accuracy: 0.8298 - val_loss: 0.3622 - val_accuracy: 0.8430\n",
      "Epoch 152/600\n",
      "250/250 [==============================] - 0s 703us/step - loss: 0.4167 - accuracy: 0.8306 - val_loss: 0.3652 - val_accuracy: 0.8405\n",
      "Epoch 153/600\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.4109 - accuracy: 0.8311 - val_loss: 0.3638 - val_accuracy: 0.8415\n",
      "Epoch 154/600\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.4092 - accuracy: 0.8326 - val_loss: 0.3614 - val_accuracy: 0.8450\n",
      "Epoch 155/600\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.4082 - accuracy: 0.8314 - val_loss: 0.3596 - val_accuracy: 0.8495\n",
      "Epoch 156/600\n",
      "250/250 [==============================] - 0s 680us/step - loss: 0.4091 - accuracy: 0.8347 - val_loss: 0.3554 - val_accuracy: 0.8565\n",
      "Epoch 157/600\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.4115 - accuracy: 0.8319 - val_loss: 0.3582 - val_accuracy: 0.8530\n",
      "Epoch 158/600\n",
      "250/250 [==============================] - 0s 675us/step - loss: 0.4100 - accuracy: 0.8331 - val_loss: 0.3593 - val_accuracy: 0.8530\n",
      "Epoch 159/600\n",
      "250/250 [==============================] - 0s 724us/step - loss: 0.4039 - accuracy: 0.8347 - val_loss: 0.3590 - val_accuracy: 0.8540\n",
      "Epoch 160/600\n",
      "250/250 [==============================] - 0s 724us/step - loss: 0.4108 - accuracy: 0.8315 - val_loss: 0.3599 - val_accuracy: 0.8495\n",
      "Epoch 161/600\n",
      "250/250 [==============================] - 0s 699us/step - loss: 0.4090 - accuracy: 0.8334 - val_loss: 0.3583 - val_accuracy: 0.8520\n",
      "Epoch 162/600\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.4062 - accuracy: 0.8339 - val_loss: 0.3565 - val_accuracy: 0.8585\n",
      "Epoch 163/600\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.4060 - accuracy: 0.8382 - val_loss: 0.3564 - val_accuracy: 0.8575\n",
      "Epoch 164/600\n",
      "250/250 [==============================] - 0s 672us/step - loss: 0.4115 - accuracy: 0.8289 - val_loss: 0.3605 - val_accuracy: 0.8490\n",
      "Epoch 165/600\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.4111 - accuracy: 0.8328 - val_loss: 0.3595 - val_accuracy: 0.8490\n",
      "Epoch 166/600\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.4058 - accuracy: 0.8366 - val_loss: 0.3571 - val_accuracy: 0.8540\n",
      "Epoch 167/600\n",
      "250/250 [==============================] - 0s 697us/step - loss: 0.4075 - accuracy: 0.8320 - val_loss: 0.3602 - val_accuracy: 0.8490\n",
      "Epoch 168/600\n",
      "250/250 [==============================] - 0s 677us/step - loss: 0.4040 - accuracy: 0.8304 - val_loss: 0.3570 - val_accuracy: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/600\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.4116 - accuracy: 0.8331 - val_loss: 0.3554 - val_accuracy: 0.8615\n",
      "Epoch 170/600\n",
      "250/250 [==============================] - 0s 672us/step - loss: 0.4137 - accuracy: 0.8291 - val_loss: 0.3566 - val_accuracy: 0.8595\n",
      "Epoch 171/600\n",
      "250/250 [==============================] - 0s 750us/step - loss: 0.4015 - accuracy: 0.8334 - val_loss: 0.3573 - val_accuracy: 0.8525\n",
      "Epoch 172/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4050 - accuracy: 0.8360 - val_loss: 0.3556 - val_accuracy: 0.8540\n",
      "Epoch 173/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4120 - accuracy: 0.8309 - val_loss: 0.3582 - val_accuracy: 0.8520\n",
      "Epoch 174/600\n",
      "250/250 [==============================] - 0s 744us/step - loss: 0.4100 - accuracy: 0.8294 - val_loss: 0.3557 - val_accuracy: 0.8560\n",
      "Epoch 175/600\n",
      "250/250 [==============================] - 0s 824us/step - loss: 0.4057 - accuracy: 0.8342 - val_loss: 0.3530 - val_accuracy: 0.8630\n",
      "Epoch 176/600\n",
      "250/250 [==============================] - 0s 792us/step - loss: 0.4037 - accuracy: 0.8372 - val_loss: 0.3558 - val_accuracy: 0.8580\n",
      "Epoch 177/600\n",
      "250/250 [==============================] - 0s 773us/step - loss: 0.4153 - accuracy: 0.8298 - val_loss: 0.3610 - val_accuracy: 0.8465\n",
      "Epoch 178/600\n",
      "250/250 [==============================] - 0s 713us/step - loss: 0.4094 - accuracy: 0.8326 - val_loss: 0.3594 - val_accuracy: 0.8485\n",
      "Epoch 179/600\n",
      "250/250 [==============================] - 0s 729us/step - loss: 0.4078 - accuracy: 0.8314 - val_loss: 0.3540 - val_accuracy: 0.8565\n",
      "Epoch 180/600\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.4095 - accuracy: 0.8353 - val_loss: 0.3565 - val_accuracy: 0.8575\n",
      "Epoch 181/600\n",
      "250/250 [==============================] - 0s 745us/step - loss: 0.4039 - accuracy: 0.8338 - val_loss: 0.3560 - val_accuracy: 0.8570\n",
      "Epoch 182/600\n",
      "250/250 [==============================] - 0s 717us/step - loss: 0.4120 - accuracy: 0.8321 - val_loss: 0.3594 - val_accuracy: 0.8445\n",
      "Epoch 183/600\n",
      "250/250 [==============================] - 0s 740us/step - loss: 0.4107 - accuracy: 0.8317 - val_loss: 0.3579 - val_accuracy: 0.8515\n",
      "Epoch 184/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4081 - accuracy: 0.8316 - val_loss: 0.3571 - val_accuracy: 0.8505\n",
      "Epoch 185/600\n",
      "250/250 [==============================] - 0s 705us/step - loss: 0.4082 - accuracy: 0.8321 - val_loss: 0.3580 - val_accuracy: 0.8475\n",
      "Epoch 186/600\n",
      "250/250 [==============================] - 0s 720us/step - loss: 0.4052 - accuracy: 0.8359 - val_loss: 0.3581 - val_accuracy: 0.8515\n",
      "Epoch 187/600\n",
      "250/250 [==============================] - 0s 731us/step - loss: 0.4084 - accuracy: 0.8335 - val_loss: 0.3595 - val_accuracy: 0.8485\n",
      "Epoch 188/600\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.4077 - accuracy: 0.8332 - val_loss: 0.3534 - val_accuracy: 0.8600\n",
      "Epoch 189/600\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.4109 - accuracy: 0.8306 - val_loss: 0.3547 - val_accuracy: 0.8555\n",
      "Epoch 190/600\n",
      "250/250 [==============================] - 0s 705us/step - loss: 0.4106 - accuracy: 0.8303 - val_loss: 0.3585 - val_accuracy: 0.8450\n",
      "Epoch 191/600\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.4101 - accuracy: 0.8304 - val_loss: 0.3592 - val_accuracy: 0.8445\n",
      "Epoch 192/600\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.4100 - accuracy: 0.8291 - val_loss: 0.3560 - val_accuracy: 0.8510\n",
      "Epoch 193/600\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.4080 - accuracy: 0.8301 - val_loss: 0.3585 - val_accuracy: 0.8430\n",
      "Epoch 194/600\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.4058 - accuracy: 0.8360 - val_loss: 0.3524 - val_accuracy: 0.8640\n",
      "Epoch 195/600\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.4042 - accuracy: 0.8346 - val_loss: 0.3553 - val_accuracy: 0.8550\n",
      "Epoch 196/600\n",
      "250/250 [==============================] - 0s 679us/step - loss: 0.4090 - accuracy: 0.8322 - val_loss: 0.3579 - val_accuracy: 0.8495\n",
      "Epoch 197/600\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.4106 - accuracy: 0.8335 - val_loss: 0.3559 - val_accuracy: 0.8535\n",
      "Epoch 198/600\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.4065 - accuracy: 0.8335 - val_loss: 0.3546 - val_accuracy: 0.8540\n",
      "Epoch 199/600\n",
      "250/250 [==============================] - 0s 672us/step - loss: 0.4047 - accuracy: 0.8334 - val_loss: 0.3524 - val_accuracy: 0.8590\n",
      "Epoch 200/600\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.4032 - accuracy: 0.8336 - val_loss: 0.3527 - val_accuracy: 0.8600\n",
      "Epoch 201/600\n",
      "250/250 [==============================] - 0s 667us/step - loss: 0.4077 - accuracy: 0.8335 - val_loss: 0.3574 - val_accuracy: 0.8520\n",
      "Epoch 202/600\n",
      "250/250 [==============================] - 0s 697us/step - loss: 0.4063 - accuracy: 0.8316 - val_loss: 0.3589 - val_accuracy: 0.8455\n",
      "Epoch 203/600\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.4059 - accuracy: 0.8325 - val_loss: 0.3596 - val_accuracy: 0.8485\n",
      "Epoch 204/600\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.4129 - accuracy: 0.8281 - val_loss: 0.3558 - val_accuracy: 0.8575\n",
      "Epoch 205/600\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.4113 - accuracy: 0.8306 - val_loss: 0.3568 - val_accuracy: 0.8515\n",
      "Epoch 206/600\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.4091 - accuracy: 0.8310 - val_loss: 0.3577 - val_accuracy: 0.8475\n",
      "Epoch 207/600\n",
      "250/250 [==============================] - 0s 697us/step - loss: 0.4047 - accuracy: 0.8339 - val_loss: 0.3569 - val_accuracy: 0.8525\n",
      "Epoch 208/600\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.4166 - accuracy: 0.8298 - val_loss: 0.3590 - val_accuracy: 0.8545\n",
      "Epoch 209/600\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.4083 - accuracy: 0.8320 - val_loss: 0.3577 - val_accuracy: 0.8520\n",
      "Epoch 210/600\n",
      "250/250 [==============================] - 0s 684us/step - loss: 0.4097 - accuracy: 0.8329 - val_loss: 0.3577 - val_accuracy: 0.8515\n",
      "Epoch 211/600\n",
      "250/250 [==============================] - 0s 731us/step - loss: 0.4062 - accuracy: 0.8349 - val_loss: 0.3587 - val_accuracy: 0.8440\n",
      "Epoch 212/600\n",
      "250/250 [==============================] - 0s 693us/step - loss: 0.4101 - accuracy: 0.8320 - val_loss: 0.3559 - val_accuracy: 0.8555\n",
      "Epoch 213/600\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.4102 - accuracy: 0.8303 - val_loss: 0.3557 - val_accuracy: 0.8555\n",
      "Epoch 214/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4108 - accuracy: 0.8322 - val_loss: 0.3608 - val_accuracy: 0.8485\n",
      "Epoch 215/600\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.4098 - accuracy: 0.8315 - val_loss: 0.3607 - val_accuracy: 0.8475\n",
      "Epoch 216/600\n",
      "250/250 [==============================] - 0s 703us/step - loss: 0.4102 - accuracy: 0.8320 - val_loss: 0.3615 - val_accuracy: 0.8480\n",
      "Epoch 217/600\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.4136 - accuracy: 0.8298 - val_loss: 0.3579 - val_accuracy: 0.8545\n",
      "Epoch 218/600\n",
      "250/250 [==============================] - 0s 719us/step - loss: 0.4118 - accuracy: 0.8304 - val_loss: 0.3570 - val_accuracy: 0.8525\n",
      "Epoch 219/600\n",
      "250/250 [==============================] - 0s 700us/step - loss: 0.4109 - accuracy: 0.8319 - val_loss: 0.3601 - val_accuracy: 0.8460\n",
      "Epoch 220/600\n",
      "250/250 [==============================] - 0s 676us/step - loss: 0.4101 - accuracy: 0.8306 - val_loss: 0.3555 - val_accuracy: 0.8570\n",
      "Epoch 221/600\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.4035 - accuracy: 0.8355 - val_loss: 0.3586 - val_accuracy: 0.8505\n",
      "Epoch 222/600\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.4092 - accuracy: 0.8350 - val_loss: 0.3555 - val_accuracy: 0.8530\n",
      "Epoch 223/600\n",
      "250/250 [==============================] - 0s 687us/step - loss: 0.4120 - accuracy: 0.8291 - val_loss: 0.3540 - val_accuracy: 0.8565\n",
      "Epoch 224/600\n",
      "250/250 [==============================] - 0s 737us/step - loss: 0.4098 - accuracy: 0.8279 - val_loss: 0.3535 - val_accuracy: 0.8595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/600\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.4072 - accuracy: 0.8328 - val_loss: 0.3553 - val_accuracy: 0.8520\n",
      "Epoch 226/600\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.4135 - accuracy: 0.8259 - val_loss: 0.3586 - val_accuracy: 0.8470\n",
      "Epoch 227/600\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.4061 - accuracy: 0.8330 - val_loss: 0.3566 - val_accuracy: 0.8500\n",
      "Epoch 228/600\n",
      "250/250 [==============================] - 0s 719us/step - loss: 0.4070 - accuracy: 0.8324 - val_loss: 0.3571 - val_accuracy: 0.8505\n",
      "Epoch 229/600\n",
      "250/250 [==============================] - 0s 735us/step - loss: 0.4115 - accuracy: 0.8288 - val_loss: 0.3551 - val_accuracy: 0.8570\n",
      "Epoch 230/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4161 - accuracy: 0.8284 - val_loss: 0.3585 - val_accuracy: 0.8495\n",
      "Epoch 231/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4097 - accuracy: 0.8307 - val_loss: 0.3569 - val_accuracy: 0.8590\n",
      "Epoch 232/600\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.4111 - accuracy: 0.8329 - val_loss: 0.3592 - val_accuracy: 0.8515\n",
      "Epoch 233/600\n",
      "250/250 [==============================] - 0s 777us/step - loss: 0.4052 - accuracy: 0.8321 - val_loss: 0.3549 - val_accuracy: 0.8555\n",
      "Epoch 234/600\n",
      "250/250 [==============================] - 0s 729us/step - loss: 0.4067 - accuracy: 0.8320 - val_loss: 0.3554 - val_accuracy: 0.8550\n",
      "Epoch 235/600\n",
      "250/250 [==============================] - 0s 720us/step - loss: 0.4016 - accuracy: 0.8369 - val_loss: 0.3528 - val_accuracy: 0.8610\n",
      "Epoch 236/600\n",
      "250/250 [==============================] - 0s 735us/step - loss: 0.4108 - accuracy: 0.8299 - val_loss: 0.3568 - val_accuracy: 0.8455\n",
      "Epoch 237/600\n",
      "250/250 [==============================] - 0s 732us/step - loss: 0.4070 - accuracy: 0.8346 - val_loss: 0.3563 - val_accuracy: 0.8500\n",
      "Epoch 238/600\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.4120 - accuracy: 0.8320 - val_loss: 0.3588 - val_accuracy: 0.8455\n",
      "Epoch 239/600\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.4044 - accuracy: 0.8359 - val_loss: 0.3512 - val_accuracy: 0.8650\n",
      "Epoch 240/600\n",
      "250/250 [==============================] - 0s 675us/step - loss: 0.4048 - accuracy: 0.8357 - val_loss: 0.3556 - val_accuracy: 0.8535\n",
      "Epoch 241/600\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.4089 - accuracy: 0.8319 - val_loss: 0.3533 - val_accuracy: 0.8600\n",
      "Epoch 242/600\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.4071 - accuracy: 0.8345 - val_loss: 0.3544 - val_accuracy: 0.8600\n",
      "Epoch 243/600\n",
      "250/250 [==============================] - 0s 699us/step - loss: 0.4162 - accuracy: 0.8288 - val_loss: 0.3584 - val_accuracy: 0.8505\n",
      "Epoch 244/600\n",
      "250/250 [==============================] - 0s 660us/step - loss: 0.4034 - accuracy: 0.8381 - val_loss: 0.3525 - val_accuracy: 0.8600\n",
      "Epoch 245/600\n",
      "250/250 [==============================] - 0s 713us/step - loss: 0.4082 - accuracy: 0.8314 - val_loss: 0.3568 - val_accuracy: 0.8535\n",
      "Epoch 246/600\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.4090 - accuracy: 0.8334 - val_loss: 0.3556 - val_accuracy: 0.8570\n",
      "Epoch 247/600\n",
      "250/250 [==============================] - 0s 692us/step - loss: 0.4124 - accuracy: 0.8301 - val_loss: 0.3546 - val_accuracy: 0.8555\n",
      "Epoch 248/600\n",
      "250/250 [==============================] - 0s 735us/step - loss: 0.4154 - accuracy: 0.8265 - val_loss: 0.3561 - val_accuracy: 0.8520\n",
      "Epoch 249/600\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.4073 - accuracy: 0.8330 - val_loss: 0.3518 - val_accuracy: 0.8595\n",
      "Epoch 250/600\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.4095 - accuracy: 0.8319 - val_loss: 0.3565 - val_accuracy: 0.8520\n",
      "Epoch 251/600\n",
      "250/250 [==============================] - 0s 669us/step - loss: 0.4147 - accuracy: 0.8286 - val_loss: 0.3561 - val_accuracy: 0.8540\n",
      "Epoch 252/600\n",
      "250/250 [==============================] - 0s 676us/step - loss: 0.4081 - accuracy: 0.8320 - val_loss: 0.3532 - val_accuracy: 0.8565\n",
      "Epoch 253/600\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.4076 - accuracy: 0.8299 - val_loss: 0.3526 - val_accuracy: 0.8570\n",
      "Epoch 254/600\n",
      "250/250 [==============================] - 0s 760us/step - loss: 0.4053 - accuracy: 0.8345 - val_loss: 0.3534 - val_accuracy: 0.8580\n",
      "Epoch 255/600\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.4165 - accuracy: 0.8288 - val_loss: 0.3554 - val_accuracy: 0.8570\n",
      "Epoch 256/600\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.4081 - accuracy: 0.8294 - val_loss: 0.3521 - val_accuracy: 0.8600\n",
      "Epoch 257/600\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.4093 - accuracy: 0.8332 - val_loss: 0.3515 - val_accuracy: 0.8610\n",
      "Epoch 258/600\n",
      "250/250 [==============================] - 0s 732us/step - loss: 0.4137 - accuracy: 0.8314 - val_loss: 0.3545 - val_accuracy: 0.8555\n",
      "Epoch 259/600\n",
      "250/250 [==============================] - 0s 700us/step - loss: 0.4090 - accuracy: 0.8316 - val_loss: 0.3504 - val_accuracy: 0.8620\n",
      "Epoch 260/600\n",
      "250/250 [==============================] - 0s 731us/step - loss: 0.4026 - accuracy: 0.8359 - val_loss: 0.3503 - val_accuracy: 0.8590\n",
      "Epoch 261/600\n",
      "250/250 [==============================] - 0s 708us/step - loss: 0.4054 - accuracy: 0.8331 - val_loss: 0.3505 - val_accuracy: 0.8590\n",
      "Epoch 262/600\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.4135 - accuracy: 0.8299 - val_loss: 0.3531 - val_accuracy: 0.8575\n",
      "Epoch 263/600\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.4093 - accuracy: 0.8299 - val_loss: 0.3502 - val_accuracy: 0.8620\n",
      "Epoch 264/600\n",
      "250/250 [==============================] - 0s 720us/step - loss: 0.4120 - accuracy: 0.8298 - val_loss: 0.3510 - val_accuracy: 0.8605\n",
      "Epoch 265/600\n",
      "250/250 [==============================] - 0s 809us/step - loss: 0.4081 - accuracy: 0.8314 - val_loss: 0.3515 - val_accuracy: 0.8610\n",
      "Epoch 266/600\n",
      "250/250 [==============================] - 0s 788us/step - loss: 0.4071 - accuracy: 0.8320 - val_loss: 0.3502 - val_accuracy: 0.8650\n",
      "Epoch 267/600\n",
      "250/250 [==============================] - 0s 720us/step - loss: 0.4048 - accuracy: 0.8353 - val_loss: 0.3495 - val_accuracy: 0.8665\n",
      "Epoch 268/600\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.4088 - accuracy: 0.8303 - val_loss: 0.3522 - val_accuracy: 0.8620\n",
      "Epoch 269/600\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.4129 - accuracy: 0.8284 - val_loss: 0.3535 - val_accuracy: 0.8620\n",
      "Epoch 270/600\n",
      "250/250 [==============================] - 0s 705us/step - loss: 0.4047 - accuracy: 0.8345 - val_loss: 0.3529 - val_accuracy: 0.8585\n",
      "Epoch 271/600\n",
      "250/250 [==============================] - 0s 717us/step - loss: 0.4067 - accuracy: 0.8338 - val_loss: 0.3528 - val_accuracy: 0.8610\n",
      "Epoch 272/600\n",
      "250/250 [==============================] - 0s 779us/step - loss: 0.4096 - accuracy: 0.8320 - val_loss: 0.3539 - val_accuracy: 0.8615\n",
      "Epoch 273/600\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.4085 - accuracy: 0.8317 - val_loss: 0.3528 - val_accuracy: 0.8625\n",
      "Epoch 274/600\n",
      "250/250 [==============================] - 0s 723us/step - loss: 0.4071 - accuracy: 0.8335 - val_loss: 0.3519 - val_accuracy: 0.8630\n",
      "Epoch 275/600\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.4045 - accuracy: 0.8341 - val_loss: 0.3542 - val_accuracy: 0.8610\n",
      "Epoch 276/600\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.4083 - accuracy: 0.8301 - val_loss: 0.3508 - val_accuracy: 0.8640\n",
      "Epoch 277/600\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.4148 - accuracy: 0.8319 - val_loss: 0.3543 - val_accuracy: 0.8540\n",
      "Epoch 278/600\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.4061 - accuracy: 0.8351 - val_loss: 0.3550 - val_accuracy: 0.8515\n",
      "Epoch 279/600\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.4081 - accuracy: 0.8339 - val_loss: 0.3546 - val_accuracy: 0.8555\n",
      "Epoch 280/600\n",
      "250/250 [==============================] - 0s 728us/step - loss: 0.4073 - accuracy: 0.8315 - val_loss: 0.3527 - val_accuracy: 0.8620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/600\n",
      "250/250 [==============================] - 0s 692us/step - loss: 0.4119 - accuracy: 0.8324 - val_loss: 0.3510 - val_accuracy: 0.8640\n",
      "Epoch 282/600\n",
      "250/250 [==============================] - 0s 680us/step - loss: 0.4092 - accuracy: 0.8325 - val_loss: 0.3535 - val_accuracy: 0.8565\n",
      "Epoch 283/600\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.4078 - accuracy: 0.8338 - val_loss: 0.3550 - val_accuracy: 0.8515\n",
      "Epoch 284/600\n",
      "250/250 [==============================] - 0s 700us/step - loss: 0.4019 - accuracy: 0.8372 - val_loss: 0.3524 - val_accuracy: 0.8625\n",
      "Epoch 285/600\n",
      "250/250 [==============================] - 0s 791us/step - loss: 0.4021 - accuracy: 0.8339 - val_loss: 0.3489 - val_accuracy: 0.8650\n",
      "Epoch 286/600\n",
      "250/250 [==============================] - 0s 713us/step - loss: 0.4096 - accuracy: 0.8321 - val_loss: 0.3511 - val_accuracy: 0.8620\n",
      "Epoch 287/600\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.4054 - accuracy: 0.8332 - val_loss: 0.3505 - val_accuracy: 0.8640\n",
      "Epoch 288/600\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.4058 - accuracy: 0.8324 - val_loss: 0.3494 - val_accuracy: 0.8660\n",
      "Epoch 289/600\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.4057 - accuracy: 0.8345 - val_loss: 0.3506 - val_accuracy: 0.8590\n",
      "Epoch 290/600\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.4094 - accuracy: 0.8338 - val_loss: 0.3516 - val_accuracy: 0.8615\n",
      "Epoch 291/600\n",
      "250/250 [==============================] - 0s 746us/step - loss: 0.4097 - accuracy: 0.8315 - val_loss: 0.3539 - val_accuracy: 0.8555\n",
      "Epoch 292/600\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.4084 - accuracy: 0.8314 - val_loss: 0.3541 - val_accuracy: 0.8580\n",
      "Epoch 293/600\n",
      "250/250 [==============================] - 0s 739us/step - loss: 0.4092 - accuracy: 0.8275 - val_loss: 0.3506 - val_accuracy: 0.8620\n",
      "Epoch 294/600\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.4042 - accuracy: 0.8331 - val_loss: 0.3503 - val_accuracy: 0.8620\n",
      "Epoch 295/600\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.4028 - accuracy: 0.8338 - val_loss: 0.3535 - val_accuracy: 0.8585\n",
      "Epoch 296/600\n",
      "250/250 [==============================] - 0s 697us/step - loss: 0.4093 - accuracy: 0.8330 - val_loss: 0.3564 - val_accuracy: 0.8560\n",
      "Epoch 297/600\n",
      "250/250 [==============================] - 0s 748us/step - loss: 0.4051 - accuracy: 0.8354 - val_loss: 0.3544 - val_accuracy: 0.8625\n",
      "Epoch 298/600\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.4035 - accuracy: 0.8353 - val_loss: 0.3501 - val_accuracy: 0.8625\n",
      "Epoch 299/600\n",
      "250/250 [==============================] - 0s 667us/step - loss: 0.4136 - accuracy: 0.8339 - val_loss: 0.3528 - val_accuracy: 0.8605\n",
      "Epoch 300/600\n",
      "250/250 [==============================] - 0s 696us/step - loss: 0.4109 - accuracy: 0.8328 - val_loss: 0.3527 - val_accuracy: 0.8600\n",
      "Epoch 301/600\n",
      "250/250 [==============================] - 0s 728us/step - loss: 0.4025 - accuracy: 0.8341 - val_loss: 0.3494 - val_accuracy: 0.8650\n",
      "Epoch 302/600\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.4051 - accuracy: 0.8314 - val_loss: 0.3501 - val_accuracy: 0.8640\n",
      "Epoch 303/600\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.4108 - accuracy: 0.8299 - val_loss: 0.3490 - val_accuracy: 0.8640\n",
      "Epoch 304/600\n",
      "250/250 [==============================] - 0s 815us/step - loss: 0.4083 - accuracy: 0.8306 - val_loss: 0.3507 - val_accuracy: 0.8610\n",
      "Epoch 305/600\n",
      "250/250 [==============================] - 0s 842us/step - loss: 0.4061 - accuracy: 0.8330 - val_loss: 0.3528 - val_accuracy: 0.8555\n",
      "Epoch 306/600\n",
      "250/250 [==============================] - 0s 701us/step - loss: 0.4023 - accuracy: 0.8335 - val_loss: 0.3512 - val_accuracy: 0.8550\n",
      "Epoch 307/600\n",
      "250/250 [==============================] - 0s 735us/step - loss: 0.4053 - accuracy: 0.8336 - val_loss: 0.3501 - val_accuracy: 0.8590\n",
      "Epoch 308/600\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.4100 - accuracy: 0.8309 - val_loss: 0.3545 - val_accuracy: 0.8560\n",
      "Epoch 309/600\n",
      "250/250 [==============================] - 0s 808us/step - loss: 0.4057 - accuracy: 0.8316 - val_loss: 0.3524 - val_accuracy: 0.8610\n",
      "Epoch 310/600\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.4116 - accuracy: 0.8298 - val_loss: 0.3569 - val_accuracy: 0.8515\n",
      "Epoch 311/600\n",
      "250/250 [==============================] - 0s 773us/step - loss: 0.4045 - accuracy: 0.8336 - val_loss: 0.3536 - val_accuracy: 0.8560\n",
      "Epoch 312/600\n",
      "250/250 [==============================] - 0s 776us/step - loss: 0.4051 - accuracy: 0.8325 - val_loss: 0.3518 - val_accuracy: 0.8585\n",
      "Epoch 313/600\n",
      "250/250 [==============================] - 0s 680us/step - loss: 0.4067 - accuracy: 0.8354 - val_loss: 0.3525 - val_accuracy: 0.8610\n",
      "Epoch 314/600\n",
      "250/250 [==============================] - 0s 739us/step - loss: 0.4101 - accuracy: 0.8334 - val_loss: 0.3547 - val_accuracy: 0.8565\n",
      "Epoch 315/600\n",
      "250/250 [==============================] - 0s 729us/step - loss: 0.4097 - accuracy: 0.8340 - val_loss: 0.3558 - val_accuracy: 0.8550\n",
      "Epoch 316/600\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.4062 - accuracy: 0.8331 - val_loss: 0.3528 - val_accuracy: 0.8580\n",
      "Epoch 317/600\n",
      "250/250 [==============================] - 0s 669us/step - loss: 0.4061 - accuracy: 0.8342 - val_loss: 0.3546 - val_accuracy: 0.8550\n",
      "Epoch 318/600\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.4098 - accuracy: 0.8311 - val_loss: 0.3547 - val_accuracy: 0.8570\n",
      "Epoch 319/600\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.4070 - accuracy: 0.8314 - val_loss: 0.3525 - val_accuracy: 0.8560\n",
      "Epoch 320/600\n",
      "250/250 [==============================] - 0s 723us/step - loss: 0.4100 - accuracy: 0.8336 - val_loss: 0.3534 - val_accuracy: 0.8590\n",
      "Epoch 321/600\n",
      "250/250 [==============================] - 0s 724us/step - loss: 0.4107 - accuracy: 0.8282 - val_loss: 0.3532 - val_accuracy: 0.8570\n",
      "Epoch 322/600\n",
      "250/250 [==============================] - 0s 685us/step - loss: 0.4074 - accuracy: 0.8299 - val_loss: 0.3549 - val_accuracy: 0.8515\n",
      "Epoch 323/600\n",
      "250/250 [==============================] - 0s 677us/step - loss: 0.4082 - accuracy: 0.8338 - val_loss: 0.3578 - val_accuracy: 0.8475\n",
      "Epoch 324/600\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.4109 - accuracy: 0.8294 - val_loss: 0.3577 - val_accuracy: 0.8515\n",
      "Epoch 325/600\n",
      "250/250 [==============================] - 0s 679us/step - loss: 0.4044 - accuracy: 0.8335 - val_loss: 0.3518 - val_accuracy: 0.8590\n",
      "Epoch 326/600\n",
      "250/250 [==============================] - 0s 708us/step - loss: 0.4077 - accuracy: 0.8306 - val_loss: 0.3536 - val_accuracy: 0.8560\n",
      "Epoch 327/600\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.4084 - accuracy: 0.8317 - val_loss: 0.3530 - val_accuracy: 0.8565\n",
      "Epoch 328/600\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.4048 - accuracy: 0.8355 - val_loss: 0.3516 - val_accuracy: 0.8595\n",
      "Epoch 329/600\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.4110 - accuracy: 0.8313 - val_loss: 0.3540 - val_accuracy: 0.8565\n",
      "Epoch 330/600\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.4093 - accuracy: 0.8326 - val_loss: 0.3558 - val_accuracy: 0.8565\n",
      "Epoch 331/600\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.4085 - accuracy: 0.8303 - val_loss: 0.3537 - val_accuracy: 0.8550\n",
      "Epoch 332/600\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.4055 - accuracy: 0.8335 - val_loss: 0.3539 - val_accuracy: 0.8575\n",
      "Epoch 333/600\n",
      "250/250 [==============================] - 0s 737us/step - loss: 0.4090 - accuracy: 0.8307 - val_loss: 0.3512 - val_accuracy: 0.8600\n",
      "Epoch 334/600\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.4035 - accuracy: 0.8326 - val_loss: 0.3518 - val_accuracy: 0.8630\n",
      "Epoch 335/600\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.4087 - accuracy: 0.8326 - val_loss: 0.3556 - val_accuracy: 0.8525\n",
      "Epoch 00335: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f5d27234c0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.compile(optimizer='adam', loss= 'binary_crossentropy', metrics='accuracy')\n",
    "ann.fit(x=X_train,y=y_train, batch_size=None, epochs=600, verbose=1, \n",
    "        callbacks=[early_stop], validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(ann.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1495  100]\n",
      " [ 187  218]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8565"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann.predict_classes(X_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use our ANN model to predict if the customer with the following informations will leave the bank:\n",
    "\n",
    "#Geography: France\n",
    "\n",
    "#Credit Score: 600\n",
    "\n",
    "#Gender: Male\n",
    "\n",
    "#Age: 40 years old\n",
    "\n",
    "#Tenure: 3 years\n",
    "\n",
    "#Balance: $ 60000\n",
    "\n",
    "#Number of Products: 2\n",
    "\n",
    "#Does this customer have a credit card ? Yes\n",
    "\n",
    "#Is this customer an Active Member: Yes\n",
    "\n",
    "#Estimated Salary: $ 50000\n",
    "\n",
    "#will the customer stay or leave ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.transform([[600, 'France', 1, 40, 3, 60000, 2, 1, 1, 50000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(ann.predict((sc.transform(ct.transform([[600, 'France', 1, 40, 3, 60000, 2, 1, 1, 50000]])))) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so the customer won't leave the bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
